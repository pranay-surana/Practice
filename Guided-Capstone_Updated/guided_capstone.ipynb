{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hitesh.hinduja/Downloads'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#print out current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step2_output.csv', 'step3_output.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>triple</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyeska Resort</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>3939</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>669.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>150</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaglecrest Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2600</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>640.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>350.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2090</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>150</td>\n",
       "      <td>36</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>152</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona Snowbowl</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11500</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>777.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>122</td>\n",
       "      <td>81</td>\n",
       "      <td>260.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11100</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>250.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>104</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name    state  summit_elev  vertical_drop  trams  fastEight  \\\n",
       "0       Alyeska Resort   Alaska         3939           2500      1          0   \n",
       "1  Eaglecrest Ski Area   Alaska         2600           1540      0          0   \n",
       "2     Hilltop Ski Area   Alaska         2090            294      0          0   \n",
       "3     Arizona Snowbowl  Arizona        11500           2300      0          0   \n",
       "4  Sunrise Park Resort  Arizona        11100           1800      0          0   \n",
       "\n",
       "   fastSixes  fastQuads  quad  triple  ...  SkiableTerrain_ac  Snow Making_ac  \\\n",
       "0          0          2     2       0  ...             1610.0           113.0   \n",
       "1          0          0     0       0  ...              640.0            60.0   \n",
       "2          0          0     0       1  ...               30.0            30.0   \n",
       "3          1          0     2       2  ...              777.0           104.0   \n",
       "4          0          1     2       3  ...              800.0            80.0   \n",
       "\n",
       "   daysOpenLastYear  yearsOpen  averageSnowfall  AdultWeekday  AdultWeekend  \\\n",
       "0               150         60            669.0          65.0          85.0   \n",
       "1                45         44            350.0          47.0          53.0   \n",
       "2               150         36             69.0          30.0          34.0   \n",
       "3               122         81            260.0          89.0          89.0   \n",
       "4               115         49            250.0          74.0          78.0   \n",
       "\n",
       "   projectedDaysOpen  NightSkiing_ac  clusters  \n",
       "0                150           550.0         0  \n",
       "1                 90             0.0         0  \n",
       "2                152            30.0         0  \n",
       "3                122             0.0         1  \n",
       "4                104            80.0         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/hitesh.hinduja/Downloads/capstone-01-master/data/processed'\n",
    "print(os.listdir(path))\n",
    "os.chdir(path)\n",
    "\n",
    "df = pd.read_csv('step3_output.csv',)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('AdultWeekday', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state\n",
      "0   Alaska\n",
      "1   Alaska\n",
      "2   Alaska\n",
      "3  Arizona\n",
      "4  Arizona\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 330 entries, 0 to 329\n",
      "Data columns (total 59 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Name                  330 non-null    object \n",
      " 1   summit_elev           330 non-null    int64  \n",
      " 2   vertical_drop         330 non-null    int64  \n",
      " 3   trams                 330 non-null    int64  \n",
      " 4   fastEight             330 non-null    int64  \n",
      " 5   fastSixes             330 non-null    int64  \n",
      " 6   fastQuads             330 non-null    int64  \n",
      " 7   quad                  330 non-null    int64  \n",
      " 8   triple                330 non-null    int64  \n",
      " 9   double                330 non-null    int64  \n",
      " 10  surface               330 non-null    int64  \n",
      " 11  total_chairs          330 non-null    int64  \n",
      " 12  Runs                  330 non-null    int64  \n",
      " 13  TerrainParks          330 non-null    int64  \n",
      " 14  LongestRun_mi         330 non-null    float64\n",
      " 15  SkiableTerrain_ac     330 non-null    float64\n",
      " 16  Snow Making_ac        330 non-null    float64\n",
      " 17  daysOpenLastYear      330 non-null    int64  \n",
      " 18  yearsOpen             330 non-null    int64  \n",
      " 19  averageSnowfall       330 non-null    float64\n",
      " 20  AdultWeekend          330 non-null    float64\n",
      " 21  projectedDaysOpen     330 non-null    int64  \n",
      " 22  NightSkiing_ac        330 non-null    float64\n",
      " 23  clusters              330 non-null    int64  \n",
      " 24  state_Alaska          330 non-null    uint8  \n",
      " 25  state_Arizona         330 non-null    uint8  \n",
      " 26  state_California      330 non-null    uint8  \n",
      " 27  state_Colorado        330 non-null    uint8  \n",
      " 28  state_Connecticut     330 non-null    uint8  \n",
      " 29  state_Idaho           330 non-null    uint8  \n",
      " 30  state_Illinois        330 non-null    uint8  \n",
      " 31  state_Indiana         330 non-null    uint8  \n",
      " 32  state_Iowa            330 non-null    uint8  \n",
      " 33  state_Maine           330 non-null    uint8  \n",
      " 34  state_Maryland        330 non-null    uint8  \n",
      " 35  state_Massachusetts   330 non-null    uint8  \n",
      " 36  state_Michigan        330 non-null    uint8  \n",
      " 37  state_Minnesota       330 non-null    uint8  \n",
      " 38  state_Missouri        330 non-null    uint8  \n",
      " 39  state_Montana         330 non-null    uint8  \n",
      " 40  state_Nevada          330 non-null    uint8  \n",
      " 41  state_New Hampshire   330 non-null    uint8  \n",
      " 42  state_New Jersey      330 non-null    uint8  \n",
      " 43  state_New Mexico      330 non-null    uint8  \n",
      " 44  state_New York        330 non-null    uint8  \n",
      " 45  state_North Carolina  330 non-null    uint8  \n",
      " 46  state_Ohio            330 non-null    uint8  \n",
      " 47  state_Oregon          330 non-null    uint8  \n",
      " 48  state_Pennsylvania    330 non-null    uint8  \n",
      " 49  state_Rhode Island    330 non-null    uint8  \n",
      " 50  state_South Dakota    330 non-null    uint8  \n",
      " 51  state_Tennessee       330 non-null    uint8  \n",
      " 52  state_Utah            330 non-null    uint8  \n",
      " 53  state_Vermont         330 non-null    uint8  \n",
      " 54  state_Virginia        330 non-null    uint8  \n",
      " 55  state_Washington      330 non-null    uint8  \n",
      " 56  state_West Virginia   330 non-null    uint8  \n",
      " 57  state_Wisconsin       330 non-null    uint8  \n",
      " 58  state_Wyoming         330 non-null    uint8  \n",
      "dtypes: float64(6), int64(17), object(1), uint8(35)\n",
      "memory usage: 73.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dfo=df[['state']] # select object type columns and then deselect name\n",
    "print(dfo.head())\n",
    "\n",
    "df1 = pd.concat([df.drop(dfo, axis=1), pd.get_dummies(dfo)], axis=1)\n",
    "\n",
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 330 entries, 0 to 329\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               330 non-null    object \n",
      " 1   summit_elev        330 non-null    int64  \n",
      " 2   vertical_drop      330 non-null    int64  \n",
      " 3   trams              330 non-null    int64  \n",
      " 4   fastEight          330 non-null    int64  \n",
      " 5   fastSixes          330 non-null    int64  \n",
      " 6   fastQuads          330 non-null    int64  \n",
      " 7   quad               330 non-null    int64  \n",
      " 8   triple             330 non-null    int64  \n",
      " 9   double             330 non-null    int64  \n",
      " 10  surface            330 non-null    int64  \n",
      " 11  total_chairs       330 non-null    int64  \n",
      " 12  Runs               330 non-null    int64  \n",
      " 13  TerrainParks       330 non-null    int64  \n",
      " 14  LongestRun_mi      330 non-null    float64\n",
      " 15  SkiableTerrain_ac  330 non-null    float64\n",
      " 16  Snow Making_ac     330 non-null    float64\n",
      " 17  daysOpenLastYear   330 non-null    int64  \n",
      " 18  yearsOpen          330 non-null    int64  \n",
      " 19  averageSnowfall    330 non-null    float64\n",
      " 20  AdultWeekend       330 non-null    float64\n",
      " 21  projectedDaysOpen  330 non-null    int64  \n",
      " 22  NightSkiing_ac     330 non-null    float64\n",
      " 23  clusters           330 non-null    int64  \n",
      "dtypes: float64(6), int64(17), object(1)\n",
      "memory usage: 62.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = df.drop('state',axis=1)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 330 entries, 0 to 329\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               330 non-null    object \n",
      " 1   trams              330 non-null    int64  \n",
      " 2   fastEight          330 non-null    int64  \n",
      " 3   fastSixes          330 non-null    int64  \n",
      " 4   fastQuads          330 non-null    int64  \n",
      " 5   quad               330 non-null    int64  \n",
      " 6   triple             330 non-null    int64  \n",
      " 7   double             330 non-null    int64  \n",
      " 8   surface            330 non-null    int64  \n",
      " 9   total_chairs       330 non-null    int64  \n",
      " 10  Runs               330 non-null    int64  \n",
      " 11  TerrainParks       330 non-null    int64  \n",
      " 12  LongestRun_mi      330 non-null    float64\n",
      " 13  SkiableTerrain_ac  330 non-null    float64\n",
      " 14  Snow Making_ac     330 non-null    float64\n",
      " 15  AdultWeekend       330 non-null    float64\n",
      " 16  NightSkiing_ac     330 non-null    float64\n",
      " 17  clusters           330 non-null    int64  \n",
      "dtypes: float64(5), int64(12), object(1)\n",
      "memory usage: 46.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df3 = df.drop(['state','summit_elev','vertical_drop','averageSnowfall','yearsOpen','daysOpenLastYear','projectedDaysOpen'], axis=1)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1750243 ,  1.3572862 ,  1.4796585 , ..., -0.11076976,\n",
       "        -0.22573306, -0.15762208],\n",
       "       [-0.53401788,  0.34294523, -0.30893969, ..., -0.11076976,\n",
       "        -0.22573306, -0.15762208],\n",
       "       [-0.6707518 , -0.97358483, -0.30893969, ..., -0.11076976,\n",
       "        -0.22573306, -0.15762208],\n",
       "       ...,\n",
       "       [ 0.86227679,  0.37569999, -0.30893969, ..., -0.11076976,\n",
       "        -0.22573306,  6.34428877],\n",
       "       [ 1.35961292, -0.23818762, -0.30893969, ..., -0.11076976,\n",
       "        -0.22573306,  6.34428877],\n",
       "       [ 1.31591169, -0.12196105, -0.30893969, ..., -0.11076976,\n",
       "        -0.22573306,  6.34428877]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X1 = df1.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df.loc[:,'AdultWeekend']\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X1)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled1 = scaler.transform(X1) \n",
    "X_scaled1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.75024298e-01,  1.35728620e+00,  1.47965850e+00, ...,\n",
       "         1.04373424e+00,  5.28388759e+00, -7.36244575e-01],\n",
       "       [-5.34017876e-01,  3.42945226e-01, -3.08939686e-01, ...,\n",
       "        -1.04690187e+00, -6.09611897e-01, -7.36244575e-01],\n",
       "       [-6.70751800e-01, -9.73584832e-01, -3.08939686e-01, ...,\n",
       "         1.11342211e+00, -2.88148289e-01, -7.36244575e-01],\n",
       "       ...,\n",
       "       [ 8.62276787e-01,  3.75699987e-01, -3.08939686e-01, ...,\n",
       "         1.02947990e-01,  5.69088000e-01,  1.35824430e+00],\n",
       "       [ 1.35961292e+00, -2.38187625e-01, -3.08939686e-01, ...,\n",
       "        -1.58381523e-03, -6.09611897e-01,  1.35824430e+00],\n",
       "       [ 1.31591169e+00, -1.21961055e-01, -3.08939686e-01, ...,\n",
       "        -1.58381523e-03, -6.09611897e-01,  1.35824430e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X2 = df2.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X2)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled2 = scaler.transform(X2) \n",
    "X_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4796585 , -0.05513178, -0.2840776 , ..., -0.1503032 ,\n",
       "         5.28388759, -0.73624458],\n",
       "       [-0.30893969, -0.05513178, -0.2840776 , ..., -0.36274889,\n",
       "        -0.6096119 , -0.73624458],\n",
       "       [-0.30893969, -0.05513178, -0.2840776 , ..., -0.48300117,\n",
       "        -0.28814829, -0.73624458],\n",
       "       ...,\n",
       "       [-0.30893969, -0.05513178, -0.2840776 , ...,  0.39884887,\n",
       "         0.569088  ,  1.3582443 ],\n",
       "       [-0.30893969, -0.05513178, -0.2840776 , ..., -0.48300117,\n",
       "        -0.6096119 ,  1.3582443 ],\n",
       "       [-0.30893969, -0.05513178, -0.2840776 , ..., -0.60325344,\n",
       "        -0.6096119 ,  1.3582443 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X3 = df3.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X3)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled3 = scaler.transform(X3) \n",
    "X_scaled3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_scaled1, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_scaled2, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_scaled3, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all first model set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred1 = model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3662666865074793"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "explained_variance_score(y_test1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.763082588095843"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.27769116948181"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
